{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from uuid import uuid4\n",
    "from time import mktime\n",
    "from random import choices\n",
    "import ciso8601 as fasttime\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import cycle, permutations, repeat\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status Reference Table (21 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_reference = [\n",
    "    {\"status_id\": 0, \"name\": \"image_pending\", \"category\": \"actionable_timed\", \"description\": \"Image under review.\"},\n",
    "    {\"status_id\": 1, \"name\": \"image_appealed\", \"category\": \"actionable_timed\", \"description\": \"Image to be reassessed.\"},\n",
    "    {\"status_id\": 2, \"name\": \"image_reported\", \"category\": \"actionable_untimed\", \"description\": \"Image reported, pending review.\"},\n",
    "    {\"status_id\": 3, \"name\": \"image_accepted\", \"category\": \"decision\", \"description\": \"Image approved for display.\"},\n",
    "    {\"status_id\": 4, \"name\": \"image_rejected\", \"category\": \"decision\", \"description\": \"Image rejected.\"},\n",
    "    {\"status_id\": 5, \"name\": \"image_marked_deletion\", \"category\": \"decision\", \"description\": \"Image marked for deletion, will automatically delete after 7 days.\"},\n",
    "    {\"status_id\": 6, \"name\": \"image_deleted\", \"category\": \"decision_final\", \"description\": \"Image deleted, do not display.\"},\n",
    "    {\"status_id\": 7, \"name\": \"user_acceptable\", \"category\": \"decision\", \"description\": \"User fine, no action neede.\"},\n",
    "    {\"status_id\": 8, \"name\": \"user_reported\", \"category\": \"actionable_untimed\", \"description\": \"User reported, pending review.\"},\n",
    "    {\"status_id\": 9, \"name\": \"user_muted\", \"category\": \"decision\", \"description\": \"User muted, cannot post comments or upload images.\"},\n",
    "    {\"status_id\": 10, \"name\": \"user_mute_appeal\", \"category\": \"actionable_untimed\", \"description\": \"User to be reassessed.\"},\n",
    "    {\"status_id\": 11, \"name\": \"user_banned\", \"category\": \"decision_final\", \"description\": \"User banned, account access restricted.\"},\n",
    "    {\"status_id\": 12, \"name\": \"comment_acceptable\", \"category\": \"decision\", \"description\": \"Comment fine, no action neede.\"},\n",
    "    {\"status_id\": 13, \"name\": \"comment_reported\", \"category\": \"actionable_untimed\", \"description\": \"Comment reported, pending review.\"},\n",
    "    {\"status_id\": 14, \"name\": \"comment_hidden\", \"category\": \"decision\", \"description\": \"Comment hidden from general view.\"},\n",
    "    {\"status_id\": 15, \"name\": \"comment_deleted\", \"category\": \"decision_final\", \"description\": \"Comment deleted, do not display.\"},\n",
    "    {\"status_id\": 16, \"name\": \"tag_pending\", \"category\": \"actionable_timed\", \"description\": \"Tag under review.\"},\n",
    "    {\"status_id\": 17, \"name\": \"tag_appealed\", \"category\": \"actionable_timed\", \"description\": \"Tag to be reassessed.\"},\n",
    "    {\"status_id\": 18, \"name\": \"tag_reported\", \"category\": \"actionable_untimed\", \"description\": \"Tag reported, pending review.\"},\n",
    "    {\"status_id\": 19, \"name\": \"tag_accepted\", \"category\": \"decision\", \"description\": \"Tag approved for use.\"},\n",
    "    {\"status_id\": 20, \"name\": \"tag_rejected\", \"category\": \"decision\", \"description\": \"Tag rejected for use.\"}\n",
    "]\n",
    "\n",
    "pd.DataFrame.from_records(status_reference).to_csv(\"./database/csv/status_reference.csv\", index=False)\n",
    "del status_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permission Reference Table (4 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "permission_reference = [\n",
    "    {\"permission_id\": 0, \"name\": \"basic\", \"description\": \"Basic user, no special permissions.\"},\n",
    "    {\"permission_id\": 1, \"name\": \"premium\", \"description\": \"Premium user, able to view deleted images.\"},\n",
    "    {\"permission_id\": 2, \"name\": \"moderator\", \"description\": \"Moderator, able to act on reports.\"},\n",
    "    {\"permission_id\": 3, \"name\": \"admin\", \"description\": \"Administrator.\"},\n",
    "]\n",
    "\n",
    "pd.DataFrame.from_records(permission_reference).to_csv(\"./database/csv/permission_reference.csv\", index=False)\n",
    "del permission_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags Table (400 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_names = [\n",
    "    \"Apple\", \"Air\", \"Conditioner\", \"Airport\",\n",
    "    \"Ambulance\", \"Aircraft\", \"Apartment\",\n",
    "    \"Arrow\", \"Antlers\", \"Apron\", \"Alligator\",\n",
    "    \"Architect\", \"Ankle\", \"Armchair\", \"Aunt\",\n",
    "    \"Ball\", \"Bermudas\", \"Beans\", \"Balloon\",\n",
    "    \"Bear\", \"Blouse\", \"Bed\", \"Bow\", \"Bread\",\n",
    "    \"Black\", \"Board\", \"Bones\", \"Bill\",\n",
    "    \"Bitterness\", \"Boxers\", \"Belt\", \"Brain\",\n",
    "    \"Buffalo\", \"Bird\", \"Baby\", \"Book\", \"Back\",\n",
    "    \"Butter\", \"Bulb\", \"Buckles\", \"Bat\", \"Bank\",\n",
    "    \"Bag\", \"Bra\", \"Boots\", \"Blazer\", \"Bikini\",\n",
    "    \"Bookcase\", \"Bookstore\", \"Bus stop\", \"Brass\",\n",
    "    \"Brother\", \"Boy\", \"Blender\", \"Bucket\",\n",
    "    \"Bakery\", \"Bow\", \"Bridge\", \"Boat\", \"Car\",\n",
    "    \"Cow\", \"Cap\", \"Cooker\", \"Cheeks\", \"Cheese\",\n",
    "    \"Credenza\", \"Carpet\", \"Crow\", \"Crest\",\n",
    "    \"Chest\", \"Chair\", \"Candy\", \"Cabinet\", \"Cat\",\n",
    "    \"Coffee\", \"Children\", \"Cookware\",\n",
    "    \"Chaise longue\", \"Chicken\", \"Casino\",\n",
    "    \"Cabin\", \"Castle\", \"Church\", \"Cafe\",\n",
    "    \"Cinema\", \"Choker\", \"Cravat\", \"Cane\",\n",
    "    \"Costume\", \"Cardigan\", \"Chocolate\", \"Crib\",\n",
    "    \"Couch\", \"Cello\", \"Cashier\", \"Composer\",\n",
    "    \"Cave\", \"Country\", \"Computer\", \"Canoe\",\n",
    "    \"Clock\", \"Dog\", \"Deer\", \"Donkey\", \"Desk\",\n",
    "    \"Desktop\", \"Dress\", \"Dolphin\", \"Doctor\",\n",
    "    \"Dentist\", \"Drum\", \"Dresser\", \"Designer\",\n",
    "    \"Detective\", \"Daughter\", \"Egg\", \"Elephant\",\n",
    "    \"Earrings\", \"Ears\", \"Eyes\", \"Estate\",\n",
    "    \"Finger\", \"Fox\", \"Frock\", \"Frog\", \"Fan\",\n",
    "    \"Freezer\", \"Fish\", \"Film\", \"Foot\",\n",
    "    \"Flag\", \"Factory\", \"Father\", \"Farm\",\n",
    "    \"Forest\", \"Flower\", \"Fruit\", \"Fork\",\n",
    "    \"Grapes\", \"Goat\", \"Gown\", \"Garlic\",\n",
    "    \"Ginger\", \"Giraffe\", \"Gauva\", \"Grains\",\n",
    "    \"Gas station\", \"Garage\", \"Gloves\",\n",
    "    \"Glasses\", \"Gift\", \"Galaxy\", \"Guitar\",\n",
    "    \"Grandmother\", \"Grandfather\", \"Governor\",\n",
    "    \"Girl\", \"Guest\", \"Hamburger\", \"Hand\",\n",
    "    \"Head\", \"Hair\", \"Heart\", \"House\", \"Horse\",\n",
    "    \"Hen\", \"Horn\", \"Hat\", \"Hammer\", \"Hostel\",\n",
    "    \"Hospital\", \"Hotel\", \"Heels\", \"Herbs\",\n",
    "    \"Host\", \"Jacket\", \"Jersey\", \"Jewelry\",\n",
    "    \"Jaw\", \"Jumper\", \"Judge\", \"Juicer\",\n",
    "    \"Keyboard\", \"Kid\", \"Kangaroo\", \"Koala\",\n",
    "    \"Knife\", \"Lemon\", \"Lion\", \"Leggings\",\n",
    "    \"Leg\", \"Laptop\", \"Library\", \"Lamb\",\n",
    "    \"London\", \"Lips\", \"Lung\", \"Lighter\",\n",
    "    \"Luggage\", \"Lamp\", \"Lawyer\", \"Mouse\",\n",
    "    \"Monkey\", \"Mouth\", \"Mango\", \"Mobile\",\n",
    "    \"Milk\", \"Music\", \"Mirror\", \"Musician\",\n",
    "    \"Mother\", \"Man\", \"Model\", \"Mall\",\n",
    "    \"Museum\", \"Market\", \"Moonlight\",\n",
    "    \"Medicine\", \"Microscope\", \"Newspaper\",\n",
    "    \"Nose\", \"Notebook\", \"Neck\", \"Noodles\",\n",
    "    \"Nurse\", \"Necklace\", \"Noise\", \"Ocean\",\n",
    "    \"Ostrich\", \"Oil\", \"Orange\", \"Onion\",\n",
    "    \"Oven\", \"Owl\", \"Paper\", \"Panda\",\n",
    "    \"Pants\", \"Palm\", \"Pasta\", \"Pumpkin\",\n",
    "    \"Pharmacist\", \"Potato\", \"Parfume\",\n",
    "    \"Panther\", \"Pad\", \"Pencil\", \"Pipe\",\n",
    "    \"Police\", \"Pen\", \"Pharmacy\",\n",
    "    \"Petrol station\", \"Police station\",\n",
    "    \"Parrot\", \"Plane\", \"Pigeon\", \"Phone\",\n",
    "    \"Peacock\", \"Pencil\", \"Pig\", \"Pouch\",\n",
    "    \"Pagoda\", \"Pyramid\", \"Purse\", \"Pancake\",\n",
    "    \"Popcorn\", \"Piano\", \"Physician\",\n",
    "    \"Photographer\", \"Professor\", \"Painter\",\n",
    "    \"Park\", \"Plant\", \"Parfume\", \"Radio\",\n",
    "    \"Razor\", \"Ribs\", \"Rainbow\", \"Ring\",\n",
    "    \"Rabbit\", \"Rice\", \"Refrigerator\",\n",
    "    \"Remote\", \"Restaurant\", \"Road\",\n",
    "    \"Surgeon\", \"Scale\", \"Shampoo\", \"Sink\",\n",
    "    \"Salt\", \"Shark\", \"Sandals\", \"Shoulder\",\n",
    "    \"Spoon\", \"Soap\", \"Sand\", \"Sheep\",\n",
    "    \"Sari\", \"Stomach\", \"Stairs\", \"Soup\",\n",
    "    \"Shoes\",  \"Scissors\", \"Sparrow\",\n",
    "    \"Shirt\", \"Suitcase\", \"Stove\",\n",
    "    \"Stairs\", \"Snowman\", \"Shower\", \"Swan\",\n",
    "    \"Suit\", \"Sweater\", \"Smoke\", \"Skirt\",\n",
    "    \"Sofa\", \"Socks\", \"Stadium\", \"Skyscraper\",\n",
    "    \"School\", \"Sunglasses\", \"Sandals\",\n",
    "    \"Slippers\", \"Shorts\", \"Sandwich\",\n",
    "    \"Strawberry\", \"Spaghetti\", \"Shrimp\",\n",
    "    \"Saxophone\", \"Sister\", \"Son\", \"Singer\",\n",
    "    \"Senator\", \"Street\", \"Supermarket\",\n",
    "    \"Swimming pool\", \"Star\", \"Sky\", \"Sun\",\n",
    "    \"Spoon\", \"Ship\", \"Smile\", \"Table\",\n",
    "    \"Turkey\", \"Tie\", \"Toes\", \"Truck\",\n",
    "    \"Train\", \"Taxi\", \"Tiger\", \"Trousers\",\n",
    "    \"Tongue\", \"Television\", \"Teacher\",\n",
    "    \"Turtle\", \"Tablet\", \"Train station\",\n",
    "    \"Toothpaste\", \"Tail\", \"Theater\",\n",
    "    \"Trench coat\", \"Tea\", \"Tomato\", \"Teen\",\n",
    "    \"Tunnel\", \"Temple\", \"Town\", \"Toothbrush\",\n",
    "    \"Tree\", \"Toy\", \"Tissue\", \"Telephone\",\n",
    "    \"Underwear\", \"Uncle\", \"Umbrella\", \"Vest\",\n",
    "    \"Voice\", \"Veterinarian\", \"Villa\", \"Violin\",\n",
    "    \"Village\", \"Vehicle\", \"Vase\", \"Wallet\",\n",
    "    \"Wolf\", \"Waist\", \"Wrist\", \"Water melon\",\n",
    "    \"Whale\", \"Water\", \"Wings\", \"Whisker\",\n",
    "    \"Watch\", \"Woman\", \"Washing machine\",\n",
    "    \"Wheelchair\", \"Waiter\", \"Wound\",\n",
    "    \"Xylophone\", \"Zebra\", \"Zoo\"\n",
    "]\n",
    "\n",
    "tag_count = len(tag_names)\n",
    "\n",
    "description = cycle(\"\")\n",
    "\n",
    "tag_categories = cycle([\"general\"])\n",
    "temp_status_id = rng.choice(\n",
    "    a=[16, 17, 18, 19, 20],\n",
    "    size=tag_count,\n",
    "    p=[0.15, 0.01, 0.01, 0.71, 0.12]\n",
    ")\n",
    "\n",
    "creation_timestamps = np.random.randint(\n",
    "    low=int(mktime(fasttime.parse_datetime(\"2009-05-14\").timetuple())),\n",
    "    high=int(mktime(fasttime.parse_datetime(\"2023-12-28\").timetuple())),\n",
    "    size=tag_count\n",
    ")\n",
    "\n",
    "tag_status = [\n",
    "    19 if t < mktime(fasttime.parse_datetime(\"2021-04-03\").timetuple()) else temp_status_id[idx]\n",
    "    for idx, t in enumerate(creation_timestamps)\n",
    "]\n",
    "\n",
    "tags = sorted([*zip(range(tag_count), tag_categories, tag_names, description, tag_status, creation_timestamps)], key=lambda x: x[-1])\n",
    "pd.DataFrame(tags, columns=[\"tag_id\", \"type_category\", \"name\", \"status_id\", \"creation_timestamps\"]).to_csv(\"./database/csv/tags_table.csv\", index=False)\n",
    "\n",
    "del tag_names, tag_categories, temp_status_id, creation_timestamps, tag_status, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users Table (500,000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_count = 500_000\n",
    "string = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+_\"\n",
    "usernames = np.apply_along_axis(\n",
    "    func1d=lambda x:\"\".join(x),\n",
    "    axis=1,\n",
    "    arr=rng.choice(a=list(string), size=(user_count, 14))\n",
    ")\n",
    "\n",
    "user_timestamps = np.sort(np.random.randint(\n",
    "    low=int(mktime(fasttime.parse_datetime(\"2009-05-20\").timetuple())),\n",
    "    high=int(mktime(fasttime.parse_datetime(\"2023-12-28\").timetuple())),\n",
    "    size=user_count\n",
    "))\n",
    "\n",
    "temp_status_id = rng.choice(\n",
    "    a=range(7, 12),\n",
    "    size=user_count,\n",
    "    p=[0.88, 0.01, 0.02, 0.01, 0.08]\n",
    ")\n",
    "\n",
    "status_id = [\n",
    "    7 if t < mktime(fasttime.parse_datetime(\"2023-12-22\").timetuple()) else temp_status_id[idx]\n",
    "    for idx, t in enumerate(user_timestamps)\n",
    "]\n",
    "\n",
    "permission_level = rng.choice(\n",
    "    a=range(4),\n",
    "    size=user_count,\n",
    "    p=[0.832388, 0.166522, 0.001064, 0.000026]\n",
    ")\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    zip(range(500_000), usernames, user_timestamps, status_id, permission_level),\n",
    "    columns=[\"user_id\", \"username\", \"creation_timestamp\", \"status_id\", \"permission_id\"]\n",
    ").to_csv(\"./database/csv/users_table.csv\")\n",
    "del user_count, string, usernames, user_timestamps, temp_status_id, status_id, permission_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Table (100,000,000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100_000\n",
    "batch_count = 100_000_000//batch_size\n",
    "\n",
    "# Image Resolution constants\n",
    "common_aspect_ratios = [(1, 1), (3, 2), (5, 4), (1, 2), (2, 1)]\n",
    "custom_uncommon_ratios = [(h, w) for h,w in permutations(range(3, 11), r=2)]\n",
    "\n",
    "image_sizes = [\"800x600\", \"1080x1080\", \"1350x1080\", \"1280x720\", \"1240x1754\", \"1960x1080\", \"3840x2160\"]\n",
    "pixelart_heights = [64, 128, 256, 512]\n",
    "custom_image_heights = [*range(300, 2050, 50)]\n",
    "\n",
    "custom_common_image_sizes = []\n",
    "for ratio in common_aspect_ratios:\n",
    "    for height in custom_image_heights:\n",
    "        custom_common_image_sizes.append(f\"{ratio[0]*height}x{ratio[1]*height}\")\n",
    "\n",
    "custom_uncommon_image_sizes = []\n",
    "for ratio in custom_uncommon_ratios:\n",
    "    for height in custom_image_heights:\n",
    "        custom_uncommon_image_sizes.append(f\"{ratio[0]*height}x{ratio[1]*height}\")\n",
    "\n",
    "custom_pixelart_sizes = []\n",
    "for ratio in common_aspect_ratios:\n",
    "    for height in pixelart_heights:\n",
    "        custom_pixelart_sizes.append(f\"{ratio[0]*height}x{ratio[1]*height}\")\n",
    "\n",
    "# Newline padding\n",
    "newline_padding = cycle(\"\\n\")\n",
    "description = cycle(\"\")\n",
    "\n",
    "# Prewriting file header\n",
    "with open(\"./database/csv/images_table.csv\", \"a+\") as file:\n",
    "    file.write(\"source_url,blob_storage_uuid,shape,upload_timestamp,upload_date,status_id,uploader_id,likes,dislikes\")\n",
    "\n",
    "    for idx in range(batch_count):\n",
    "        index = range(batch_size*idx, batch_size*(idx+1))\n",
    "        \n",
    "        # Image URLs and UUIDs\n",
    "        urls = np.array([\n",
    "            f\"https://www.{tup[0]}.{tup[1]}.{tup[2]}.{tup[3]}\"\n",
    "            for tup in rng.choice(a=list(range(256)), size=(batch_size, 4))\n",
    "        ])\n",
    "\n",
    "        blob_uuids = np.array([f\"{uuid4().bytes}\" for _ in range(batch_size)])\n",
    "\n",
    "        # Image Resolutions\n",
    "        image_shape = rng.choice(\n",
    "            [\n",
    "                *image_sizes,\n",
    "                *custom_common_image_sizes,\n",
    "                *custom_uncommon_image_sizes,\n",
    "                *custom_pixelart_sizes,\n",
    "            ],\n",
    "            size=batch_size,\n",
    "            p=[\n",
    "                0.03, 0.06, 0.10, 0.06, 0.03, 0.39, 0.20,\n",
    "                *repeat(0.08/len(custom_common_image_sizes), len(custom_common_image_sizes)),\n",
    "                *repeat(0.04/len(custom_uncommon_image_sizes), len(custom_uncommon_image_sizes)),\n",
    "                *repeat(0.01/len(custom_pixelart_sizes), len(custom_pixelart_sizes)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Dates and timestamps\n",
    "        image_timestamps = np.sort(np.random.randint(\n",
    "            low=int(mktime(fasttime.parse_datetime(\"2009-05-14\").timetuple())),\n",
    "            high=int(mktime(fasttime.parse_datetime(\"2023-12-28\").timetuple())),\n",
    "            size=batch_size\n",
    "        ))\n",
    "\n",
    "        image_dates = np.array([\n",
    "            mktime(fasttime.parse_datetime(t).date().timetuple())\n",
    "            for t in image_timestamps.astype(\"datetime64[s]\").astype(str)\n",
    "        ])\n",
    "\n",
    "        # Status ID\n",
    "        temp_status_id = rng.choice(\n",
    "            a=range(7),\n",
    "            size=batch_size,\n",
    "            p=[0.05, 0.01, 0.02, 0.74, 0.03, 0.01, 0.14]\n",
    "        )\n",
    "\n",
    "        image_status = np.array([\n",
    "            3 if t < int(mktime(fasttime.parse_datetime(\"2023-12-21\").timetuple())) else temp_status_id[idx]\n",
    "            for idx, t in enumerate(image_timestamps)\n",
    "        ])\n",
    "\n",
    "        # Uploader ID\n",
    "        uploader_id = np.random.randint(low=0, high=500_000, size=batch_size)\n",
    "\n",
    "        # Likes and Dislike\n",
    "        likes = np.random.geometric(0.01, size=batch_size)\n",
    "        dislikes = np.random.geometric(0.02, size=batch_size)\n",
    "\n",
    "        file.writelines(\n",
    "            (\n",
    "                \",\".join(row)\n",
    "                for row\n",
    "                in zip(\n",
    "                    index, urls.astype(str), blob_uuids.astype(str),\n",
    "                    image_shape.astype(str), image_timestamps.astype(str),\n",
    "                    image_dates.astype(str), image_status.astype(str),\n",
    "                    description, uploader_id.astype(str), likes.astype(str),\n",
    "                    dislikes.astype(str), newline_padding\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "del (\n",
    "    batch_size, batch_count, common_aspect_ratios, custom_uncommon_ratios, image_sizes, pixelart_heights, custom_image_heights,\n",
    "    custom_pixelart_sizes, custom_common_image_sizes, custom_uncommon_image_sizes, ratio, height, idx, urls, blob_uuids,\n",
    "    image_shape, image_timestamps, image_dates, temp_status_id, image_status, uploader_id, likes, dislikes, newline_padding,\n",
    "    description, index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments Table (50,000,000 rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50_000\n",
    "batch_count = 50_000_000//batch_size\n",
    "string = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "\n",
    "# Newline padding\n",
    "newline_padding = cycle(\"\\n\")\n",
    "\n",
    "with open(\"./database/csv/comments_table.csv\", \"a+\") as file:\n",
    "    file.write(\"status_id,content,creation_timestamp,edited,likes,dislikes\")\n",
    "\n",
    "    for idx in range(batch_count):\n",
    "        index = np.arange(batch_size*idx, batch_size*(idx+1)).astype(str)\n",
    "\n",
    "        comment_content = np.apply_along_axis(\n",
    "            func1d=lambda x: \" \".join(x),\n",
    "            axis=1,\n",
    "            arr=np.apply_along_axis(\n",
    "                func1d=lambda x:\"\".join(x),\n",
    "                axis=1,\n",
    "                arr=rng.choice(a=list(string), size=(batch_size, 6, 8))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        comment_timestamps = np.sort(np.random.randint(\n",
    "            low=int(mktime(fasttime.parse_datetime(\"2009-05-14\").timetuple())),\n",
    "            high=int(mktime(fasttime.parse_datetime(\"2023-12-28\").timetuple())),\n",
    "            size=batch_size\n",
    "        ))\n",
    "\n",
    "        temp_status_id = rng.choice(\n",
    "            a=range(12, 16),\n",
    "            size=batch_size,\n",
    "            p=[0.97, 0.0015, 0.0085, 0.02]\n",
    "        )\n",
    "\n",
    "        image_status = np.array([\n",
    "            12 if t < int(mktime(fasttime.parse_datetime(\"2023-12-21\").timetuple())) else temp_status_id[idx]\n",
    "            for idx, t in enumerate(comment_timestamps)\n",
    "        ])\n",
    "\n",
    "        comment_edited = np.random.randint(low=0, high=2, size=batch_size)\n",
    "        comment_likes = np.random.geometric(0.1, size=batch_size)\n",
    "        comment_dislikes = np.random.geometric(0.2, size=batch_size)\n",
    "\n",
    "        file.writelines(\n",
    "            (\n",
    "                \",\".join(row)\n",
    "                for row\n",
    "                in zip(\n",
    "                    index,\n",
    "                    temp_status_id.astype(str), comment_content.astype(str), comment_timestamps.astype(str),\n",
    "                    comment_edited.astype(str), comment_likes.astype(str), comment_dislikes.astype(str),\n",
    "                    newline_padding\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "del (\n",
    "    batch_size, batch_count, newline_padding, file, idx, temp_status_id,\n",
    "    image_status, comment_content, comment_timestamps, comment_edited,\n",
    "    comment_likes, comment_dislikes, index, string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Tag Junction Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50_000\n",
    "batch_count = 100_000_000//batch_size\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
